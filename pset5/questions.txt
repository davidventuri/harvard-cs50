PRE-SOLUTION QUESTIONS

0. What is pneumonoultramicroscopicsilicovolcanoconiosis?
        Pneumonoultramicroscopicsilicovolcanoconiosis refers to a lung disease 
        that is otherwise known as silicosis. It is the longestword in the 
        English language published in a dictionary.
1. According to its man page, what does getrusage do?
        getrusage returns resource usage measures for "int who", which is always
        RUSAGE_SELF in speller.c. Specifying RUSAGE_SELF returns resource usage 
        statistics for the calling process, which is the sum of resources used 
        by all threads in the process.
2. Per that same man page, how many members are in a variable of type struct 
   rusage?
        There are 16 members in a variable of type struct rusage. They are also 
        listed on this page: http://linux.die.net/man/2/getrusage.
3. Why do you think we pass before and after by reference (instead of by value) 
   to calculate, even though we’re not changing their contents?
        We pass before and after by reference (instead of by value) to the 
        function "calculate" because passing large structs by value is slow and
        takes up a lot of memory. If you're passing or returning structs by 
        value, copies of those structs will get placed on the stack, potentially
        causing stack overflow.
4. Explain as precisely as possible, in a paragraph or more, how main goes about 
   reading words from a file. In other words, convince us that you indeed 
   understand how that function’s for loop works.
        The key aspect of the for loop is the c = fgetc(fp) function call. fgetc
        gets the next character (an unsigned char) from fp and advances the 
        position indicator in fp until the end of the file (EOF) is reached. As
        each character is received, it is put through an if(if)-elseif-elseif 
        logical sequence. Summarizing the sequence: 1) If the character is an 
        alphabetical character or an apostrophe that is not at index 0 of the 
        word, the character is appended to the word array. 2) Else if the 
        character is numerical, the word is ignored and we skip ahead to the 
        next word (which is found after a space). 3) Else if we hit a space or 
        punctuation, we must have found a whole word so we terminate the word by
        adding \0 to the word array.
5. Why do you think we used fgetc to read each word’s characters one at a time 
   rather than use fscanf with a format string like "%s" to read whole words at 
   a time? Put another way, what problems might arise by relying on fscanf alone?
        fscanf with a format string like "%s" will read subsequent characters 
        until a whitespace is found (whitespace characters are considered to be 
        blank, newline and tab). Because words within the txt files sometimes 
        end with punctuation, fscanf will view them as being part of the word, 
        which complicates the reading procedure. In addition, if a longer string
        than expected was read using fscanf (e.g. a jibberish string like asdfba
        asdkdfawemflkasciaoeufalkesfasldkfjaoiwefjaslkdmcalksdfiwoefalskdfamsdcl
        asdflkasdlkmceaasdfasdf..., which could be included in a text file from
        a malicious source that is trying to break our program), we could 
        overwrite important data in memory or cause a segmentation fault.
6. Why do you think we declared the parameters for check and load as const?
        With const char* parameter, we prevent changes to the string that 
        parameter is pointing at through parameter (i.e. const pointers prevent 
        changing the data pointed to)/ The parameters for check (const char* word) 
        and load (const char* dictionary) are declared as const pointers because
        we want to prevent changes to a read word and the dictionary we are using.
        
POST-SOLUTION QUESTIONS

7. What data structure(s) did you use to implement your spell-checker? Be sure 
   not to leave your answer at just "hash table," "trie," or the like. Expound 
   on what’s inside each of your "nodes."
        I used a hash table. Each bucket in the has table had a linked list of
        node structs. Each node struct contains two members - 1) a char array 
        called word and 2) a pointer to a new node called next.
8. How slow was your code the first time you got it working correctly?
        My code wasn't slow at all! The first time I got it fully working was
        the total time was hovering between 0.05 and 0.08 seconds (oftentimes
        beating the staff solution). The main issue in getting my code fully
        working was getting the word argument down to lowercase in the check
        function (e.g. incompatible types, dealing with consts, etc.) - my
        program was incorrectly labeling correctly spelled words as misspelled.
9. What kinds of changes, if any, did you make to your code in order to improve 
   its performance?
        I didn't choose to make any performance changes. The hash function I used
        was very effective and my solution using non-sorted linked lists was
        beating the staff solution right out of the gate. Using a sorted linked
        list would increase the time of my load but cut down the time of my check,
        a trade off I estimate wouldn't be worth it since the number of buckets
        in my hash table is 65536 and the number of words in the large dictionary
        is 143091.
